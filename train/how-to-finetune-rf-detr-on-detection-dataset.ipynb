{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwzfrPKyTqDc"
      },
      "source": [
        "### Check GPU availability\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `T4 GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms0ps6ZCT2xs",
        "outputId": "5ed5b248-03f8-40c0-f70b-790f1da7a24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jan  9 01:51:07 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 5070 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
            "|  0%   32C    P1             39W /  300W |     769MiB /  16303MiB |      2%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A            2821      G   /usr/lib/xorg/Xorg                      138MiB |\n",
            "|    0   N/A  N/A            3022      G   /usr/bin/gnome-shell                     28MiB |\n",
            "|    0   N/A  N/A            3629      G   ...exec/xdg-desktop-portal-gnome          5MiB |\n",
            "|    0   N/A  N/A            3806      C   /usr/NX/bin/nxnode.bin                  257MiB |\n",
            "|    0   N/A  N/A            4025      G   ...rack-uuid=3190708988185955192         76MiB |\n",
            "|    0   N/A  N/A            4666      G   /usr/bin/nautilus                        19MiB |\n",
            "|    0   N/A  N/A           15205      G   /usr/share/code/code                    169MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSbiL1I6T8JY"
      },
      "source": [
        "### Install dependencies\n",
        "\n",
        "Installs RF-DETR version 1.2.1 or higher (which includes the new Nano, Small, and Medium checkpoints), along with Supervision for benchmarking and Roboflow for pulling datasets and uploading models to the Roboflow platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3CbzMY6wITlr"
      },
      "outputs": [],
      "source": [
        "!pip install -q rfdetr==1.2.1 supervision==0.26.1 roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK6zkzY1lPtw"
      },
      "source": [
        "## Download Dataset from Roboflow Universe\n",
        "\n",
        "RF-DETR expects the dataset to be in COCO format. Divide your dataset into three subdirectories: `train`, `valid`, and `test`. Each subdirectory should contain its own `_annotations.coco.json` file that holds the annotations for that particular split, along with the corresponding image files. Below is an example of the directory structure:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "├── train/\n",
        "│   ├── _annotations.coco.json\n",
        "│   ├── image1.jpg\n",
        "│   ├── image2.jpg\n",
        "│   └── ... (other image files)\n",
        "├── valid/\n",
        "│   ├── _annotations.coco.json\n",
        "│   ├── image1.jpg\n",
        "│   ├── image2.jpg\n",
        "│   └── ... (other image files)\n",
        "└── test/\n",
        "    ├── _annotations.coco.json\n",
        "    ├── image1.jpg\n",
        "    ├── image2.jpg\n",
        "    └── ... (other image files)\n",
        "```\n",
        "\n",
        "[Roboflow](https://roboflow.com/annotate) allows you to create object detection datasets from scratch or convert existing datasets from formats like YOLO, and then export them in COCO JSON format for training. You can also explore [Roboflow Universe](https://universe.roboflow.com/) to find pre-labeled datasets for a range of use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQkMUyB0lROT",
        "outputId": "39093305-1fba-4267-d4a2-9a775324070e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Playing-Cards-4 to coco:: 100%|██████████| 2122319/2122319 [02:27<00:00, 14414.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Playing-Cards-4 in coco:: 100%|██████████| 24241/24241 [00:03<00:00, 6587.80it/s]\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"jNNh2gmG3E4aDKPlvoAp\")\n",
        "project = rf.workspace(\"augmented-startups\").project(\"playing-cards-ow27d\")\n",
        "version = project.version(4)\n",
        "dataset = version.download(\"coco\")\n",
        "                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmT8f_bAq3zX"
      },
      "source": [
        "## Train RF-DETR on custom dataset\n",
        "\n",
        "### Choose the right `batch_size`\n",
        "\n",
        "Different GPUs have different amounts of VRAM (video memory), which limits how much data they can handle at once during training. To make training work well on any machine, you can adjust two settings: `batch_size` and `grad_accum_steps`. These control how many samples are processed at a time. The key is to keep their product equal to 16 — that’s our recommended total batch size. For example, on powerful GPUs like the A100, set `batch_size=16` and `grad_accum_steps=1`. On smaller GPUs like the T4, use `batch_size=4` and `grad_accum_steps=4`. We use a method called gradient accumulation, which lets the model simulate training with a larger batch size by gradually collecting updates before adjusting the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UvmuIammK9s",
        "outputId": "4cd9ac2c-99ff-4a37-a401-20b8f8710110"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "rf-detr-nano.pth: 100%|██████████| 349M/349M [00:24<00:00, 15.1MiB/s]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
            "Using patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
            "Loading pretrain weights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "num_classes mismatch: model has 90 classes, but your dataset has 53 classes\n",
            "reinitializing your detection head with 53 classes.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to initialize TensorBoard. Logging is turned off for this session.  Run 'pip install tensorboard' to enable logging.\n",
            "Not using distributed mode\n",
            "git:\n",
            "  sha: 62b4983f894cfd8dcd28148f3548ce74cc2d6f88, status: clean, branch: main\n",
            "\n",
            "Namespace(num_classes=53, grad_accum_steps=2, amp=True, lr=0.0001, lr_encoder=0.00015, batch_size=8, weight_decay=0.0001, epochs=80, lr_drop=100, clip_max_norm=0.1, lr_vit_layer_decay=0.8, lr_component_decay=0.7, do_benchmark=False, dropout=0, drop_path=0.0, drop_mode='standard', drop_schedule='constant', cutoff_epoch=0, pretrained_encoder=None, pretrain_weights='rf-detr-nano.pth', pretrain_exclude_keys=None, pretrain_keys_modify_to_load=None, pretrained_distiller=None, encoder='dinov2_windowed_small', vit_encoder_num_layers=12, window_block_indexes=None, position_embedding='sine', out_feature_indexes=[3, 6, 9, 12], freeze_encoder=False, layer_norm=True, rms_norm=False, backbone_lora=False, force_no_pretrain=False, dec_layers=2, dim_feedforward=2048, hidden_dim=256, sa_nheads=8, ca_nheads=16, num_queries=300, group_detr=13, two_stage=True, projector_scale=['P4'], lite_refpoint_refine=True, num_select=300, dec_n_points=2, decoder_norm='LN', bbox_reparam=True, freeze_batch_norm=False, set_cost_class=2, set_cost_bbox=5, set_cost_giou=2, cls_loss_coef=1.0, bbox_loss_coef=5, giou_loss_coef=2, focal_alpha=0.25, aux_loss=True, sum_group_losses=False, use_varifocal_loss=False, use_position_supervised_loss=False, ia_bce_loss=True, dataset_file='roboflow', coco_path=None, dataset_dir='/home/faruk/Documents/nvidia-da/poker-card/train/Playing-Cards-4', square_resize_div_64=True, output_dir='output', dont_save_weights=False, checkpoint_interval=10, seed=42, resume='', start_epoch=0, eval=False, use_ema=True, ema_decay=0.993, ema_tau=100, num_workers=2, device='cuda', world_size=1, dist_url='env://', sync_bn=True, fp16_eval=False, encoder_only=False, backbone_only=False, resolution=384, use_cls_token=False, multi_scale=True, expanded_scales=True, do_random_resize_via_padding=False, warmup_epochs=0, lr_scheduler='step', lr_min_factor=0.0, early_stopping=False, early_stopping_patience=10, early_stopping_min_delta=0.001, early_stopping_use_ema=False, gradient_checkpointing=False, patch_size=16, num_windows=2, positional_encoding_size=24, tensorboard=True, wandb=False, project=None, run=None, class_names=['10C', '10D', '10H', '10S', '2C', '2D', '2H', '2S', '3C', '3D', '3H', '3S', '4C', '4D', '4H', '4S', '5C', '5D', '5H', '5S', '6C', '6D', '6H', '6S', '7C', '7D', '7H', '7S', '8C', '8D', '8H', '8S', '9C', '9D', '9H', '9S', 'AC', 'AD', 'AH', 'AS', 'JC', 'JD', 'JH', 'JS', 'KC', 'KD', 'KH', 'KS', 'QC', 'QD', 'QH', 'QS'], run_test=True, distributed=False)\n",
            "number of params: 30330574\n",
            "[544]\n",
            "loading annotations into memory...\n",
            "Done (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "[544]\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[544]\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Get benchmark\n",
            "Start training\n",
            "Grad accum steps:  2\n",
            "Total batch size:  16\n",
            "LENGTH OF DATA LOADER: 1325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
            "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [   0/1325]  eta: 0:39:40  lr: 0.000100  class_error: 92.80  loss: 8.8440 (8.8440)  loss_ce: 0.6428 (0.6428)  loss_bbox: 0.7125 (0.7125)  loss_giou: 1.4183 (1.4183)  loss_ce_0: 0.6098 (0.6098)  loss_bbox_0: 0.8578 (0.8578)  loss_giou_0: 1.5182 (1.5182)  loss_ce_enc: 0.5793 (0.5793)  loss_bbox_enc: 0.9328 (0.9328)  loss_giou_enc: 1.5725 (1.5725)  loss_ce_unscaled: 0.6428 (0.6428)  class_error_unscaled: 92.8040 (92.8040)  loss_bbox_unscaled: 0.1425 (0.1425)  loss_giou_unscaled: 0.7091 (0.7091)  cardinality_error_unscaled: 3892.3750 (3892.3750)  loss_ce_0_unscaled: 0.6098 (0.6098)  loss_bbox_0_unscaled: 0.1716 (0.1716)  loss_giou_0_unscaled: 0.7591 (0.7591)  cardinality_error_0_unscaled: 3893.1250 (3893.1250)  loss_ce_enc_unscaled: 0.5793 (0.5793)  loss_bbox_enc_unscaled: 0.1866 (0.1866)  loss_giou_enc_unscaled: 0.7862 (0.7862)  cardinality_error_enc_unscaled: 3885.2500 (3885.2500)  time: 1.7964  data: 0.4087  max mem: 3528\n",
            "Epoch: [0]  [  10/1325]  eta: 0:10:23  lr: 0.000100  class_error: 99.76  loss: 6.1464 (6.4537)  loss_ce: 1.0813 (1.0250)  loss_bbox: 0.2165 (0.2604)  loss_giou: 0.6847 (0.7792)  loss_ce_0: 1.0205 (0.9730)  loss_bbox_0: 0.2391 (0.3132)  loss_giou_0: 0.7913 (0.8738)  loss_ce_enc: 0.9621 (0.9247)  loss_bbox_enc: 0.2659 (0.3434)  loss_giou_enc: 0.8907 (0.9610)  loss_ce_unscaled: 1.0813 (1.0250)  class_error_unscaled: 99.5192 (98.5372)  loss_bbox_unscaled: 0.0433 (0.0521)  loss_giou_unscaled: 0.3423 (0.3896)  cardinality_error_unscaled: 3892.3750 (3892.2273)  loss_ce_0_unscaled: 1.0205 (0.9730)  loss_bbox_0_unscaled: 0.0478 (0.0626)  loss_giou_0_unscaled: 0.3957 (0.4369)  cardinality_error_0_unscaled: 3890.6250 (3887.7386)  loss_ce_enc_unscaled: 0.9621 (0.9247)  loss_bbox_enc_unscaled: 0.0532 (0.0687)  loss_giou_enc_unscaled: 0.4454 (0.4805)  cardinality_error_enc_unscaled: 3877.6250 (3751.8409)  time: 0.4741  data: 0.0543  max mem: 4557\n",
            "Epoch: [0]  [  20/1325]  eta: 0:09:20  lr: 0.000100  class_error: 96.39  loss: 5.7363 (6.0061)  loss_ce: 1.1507 (1.1115)  loss_bbox: 0.1383 (0.1894)  loss_giou: 0.5273 (0.6370)  loss_ce_0: 1.1146 (1.0728)  loss_bbox_0: 0.1657 (0.2232)  loss_giou_0: 0.6249 (0.7076)  loss_ce_enc: 1.0649 (1.0243)  loss_bbox_enc: 0.1790 (0.2509)  loss_giou_enc: 0.6979 (0.7893)  loss_ce_unscaled: 1.1507 (1.1115)  class_error_unscaled: 98.5577 (97.6194)  loss_bbox_unscaled: 0.0277 (0.0379)  loss_giou_unscaled: 0.2636 (0.3185)  cardinality_error_unscaled: 3890.2500 (3886.0060)  loss_ce_0_unscaled: 1.1146 (1.0728)  loss_bbox_0_unscaled: 0.0331 (0.0446)  loss_giou_0_unscaled: 0.3125 (0.3538)  cardinality_error_0_unscaled: 3876.1250 (3877.1488)  loss_ce_enc_unscaled: 1.0649 (1.0243)  loss_bbox_enc_unscaled: 0.0358 (0.0502)  loss_giou_enc_unscaled: 0.3490 (0.3947)  cardinality_error_enc_unscaled: 3872.7500 (3783.1429)  time: 0.3608  data: 0.0345  max mem: 4859\n",
            "Epoch: [0]  [  30/1325]  eta: 0:08:47  lr: 0.000100  class_error: 93.75  loss: 5.3744 (5.7909)  loss_ce: 1.2394 (1.1571)  loss_bbox: 0.0997 (0.1583)  loss_giou: 0.4179 (0.5649)  loss_ce_0: 1.2339 (1.1261)  loss_bbox_0: 0.1034 (0.1831)  loss_giou_0: 0.4381 (0.6192)  loss_ce_enc: 1.1529 (1.0805)  loss_bbox_enc: 0.1318 (0.2074)  loss_giou_enc: 0.5573 (0.6944)  loss_ce_unscaled: 1.2394 (1.1571)  class_error_unscaled: 96.3942 (96.6926)  loss_bbox_unscaled: 0.0199 (0.0317)  loss_giou_unscaled: 0.2089 (0.2825)  cardinality_error_unscaled: 3867.0000 (3877.6734)  loss_ce_0_unscaled: 1.2339 (1.1261)  loss_bbox_0_unscaled: 0.0207 (0.0366)  loss_giou_0_unscaled: 0.2191 (0.3096)  cardinality_error_0_unscaled: 3855.5000 (3859.0645)  loss_ce_enc_unscaled: 1.1529 (1.0805)  loss_bbox_enc_unscaled: 0.0264 (0.0415)  loss_giou_enc_unscaled: 0.2786 (0.3472)  cardinality_error_enc_unscaled: 3873.0000 (3794.2903)  time: 0.3710  data: 0.0358  max mem: 4861\n",
            "Epoch: [0]  [  40/1325]  eta: 0:08:29  lr: 0.000100  class_error: 80.29  loss: 5.2353 (5.6527)  loss_ce: 1.2783 (1.1885)  loss_bbox: 0.0805 (0.1395)  loss_giou: 0.3757 (0.5164)  loss_ce_0: 1.2656 (1.1628)  loss_bbox_0: 0.0840 (0.1590)  loss_giou_0: 0.3735 (0.5594)  loss_ce_enc: 1.2186 (1.1215)  loss_bbox_enc: 0.1058 (0.1801)  loss_giou_enc: 0.4444 (0.6255)  loss_ce_unscaled: 1.2783 (1.1885)  class_error_unscaled: 91.3462 (95.0661)  loss_bbox_unscaled: 0.0161 (0.0279)  loss_giou_unscaled: 0.1878 (0.2582)  cardinality_error_unscaled: 3857.7500 (3873.8598)  loss_ce_0_unscaled: 1.2656 (1.1628)  loss_bbox_0_unscaled: 0.0168 (0.0318)  loss_giou_0_unscaled: 0.1867 (0.2797)  cardinality_error_0_unscaled: 3802.7500 (3845.7104)  loss_ce_enc_unscaled: 1.2186 (1.1215)  loss_bbox_enc_unscaled: 0.0212 (0.0360)  loss_giou_enc_unscaled: 0.2222 (0.3128)  cardinality_error_enc_unscaled: 3874.6250 (3768.4939)  time: 0.3627  data: 0.0218  max mem: 4861\n",
            "Epoch: [0]  [  50/1325]  eta: 0:08:12  lr: 0.000100  class_error: 96.15  loss: 5.1901 (5.5842)  loss_ce: 1.3025 (1.2055)  loss_bbox: 0.0738 (0.1293)  loss_giou: 0.3424 (0.4929)  loss_ce_0: 1.2901 (1.1810)  loss_bbox_0: 0.0773 (0.1460)  loss_giou_0: 0.3553 (0.5322)  loss_ce_enc: 1.2585 (1.1441)  loss_bbox_enc: 0.0919 (0.1640)  loss_giou_enc: 0.4004 (0.5892)  loss_ce_unscaled: 1.3025 (1.2055)  class_error_unscaled: 91.5865 (94.9802)  loss_bbox_unscaled: 0.0148 (0.0259)  loss_giou_unscaled: 0.1712 (0.2465)  cardinality_error_unscaled: 3857.0000 (3869.2132)  loss_ce_0_unscaled: 1.2901 (1.1810)  loss_bbox_0_unscaled: 0.0155 (0.0292)  loss_giou_0_unscaled: 0.1776 (0.2661)  cardinality_error_0_unscaled: 3798.7500 (3837.6912)  loss_ce_enc_unscaled: 1.2585 (1.1441)  loss_bbox_enc_unscaled: 0.0184 (0.0328)  loss_giou_enc_unscaled: 0.2002 (0.2946)  cardinality_error_enc_unscaled: 3876.3750 (3740.5858)  time: 0.3537  data: 0.0218  max mem: 4861\n",
            "Epoch: [0]  [  60/1325]  eta: 0:08:01  lr: 0.000100  class_error: 99.04  loss: 5.2420 (5.5424)  loss_ce: 1.2923 (1.2174)  loss_bbox: 0.0862 (0.1233)  loss_giou: 0.3661 (0.4784)  loss_ce_0: 1.2883 (1.1954)  loss_bbox_0: 0.0821 (0.1376)  loss_giou_0: 0.3648 (0.5122)  loss_ce_enc: 1.2543 (1.1610)  loss_bbox_enc: 0.0963 (0.1534)  loss_giou_enc: 0.4140 (0.5636)  loss_ce_unscaled: 1.2923 (1.2174)  class_error_unscaled: 95.1923 (94.8525)  loss_bbox_unscaled: 0.0172 (0.0247)  loss_giou_unscaled: 0.1830 (0.2392)  cardinality_error_unscaled: 3826.5000 (3859.2070)  loss_ce_0_unscaled: 1.2883 (1.1954)  loss_bbox_0_unscaled: 0.0164 (0.0275)  loss_giou_0_unscaled: 0.1824 (0.2561)  cardinality_error_0_unscaled: 3777.1250 (3821.9754)  loss_ce_enc_unscaled: 1.2543 (1.1610)  loss_bbox_enc_unscaled: 0.0193 (0.0307)  loss_giou_enc_unscaled: 0.2070 (0.2818)  cardinality_error_enc_unscaled: 3859.6250 (3728.5102)  time: 0.3481  data: 0.0216  max mem: 4861\n",
            "Epoch: [0]  [  70/1325]  eta: 0:07:53  lr: 0.000100  class_error: 90.87  loss: 5.2436 (5.5077)  loss_ce: 1.2901 (1.2274)  loss_bbox: 0.0855 (0.1180)  loss_giou: 0.3695 (0.4665)  loss_ce_0: 1.2896 (1.2063)  loss_bbox_0: 0.0821 (0.1308)  loss_giou_0: 0.3642 (0.4975)  loss_ce_enc: 1.2695 (1.1761)  loss_bbox_enc: 0.0856 (0.1442)  loss_giou_enc: 0.3862 (0.5408)  loss_ce_unscaled: 1.2901 (1.2274)  class_error_unscaled: 90.8654 (93.9466)  loss_bbox_unscaled: 0.0171 (0.0236)  loss_giou_unscaled: 0.1848 (0.2333)  cardinality_error_unscaled: 3818.0000 (3855.4366)  loss_ce_0_unscaled: 1.2896 (1.2063)  loss_bbox_0_unscaled: 0.0164 (0.0262)  loss_giou_0_unscaled: 0.1821 (0.2488)  cardinality_error_0_unscaled: 3724.0000 (3804.9560)  loss_ce_enc_unscaled: 1.2695 (1.1761)  loss_bbox_enc_unscaled: 0.0171 (0.0288)  loss_giou_enc_unscaled: 0.1931 (0.2704)  cardinality_error_enc_unscaled: 3847.6250 (3721.2641)  time: 0.3530  data: 0.0212  max mem: 4861\n",
            "Epoch: [0]  [  80/1325]  eta: 0:07:42  lr: 0.000100  class_error: 84.86  loss: 5.2185 (5.4731)  loss_ce: 1.3154 (1.2380)  loss_bbox: 0.0720 (0.1128)  loss_giou: 0.3559 (0.4526)  loss_ce_0: 1.3007 (1.2182)  loss_bbox_0: 0.0733 (0.1243)  loss_giou_0: 0.3642 (0.4807)  loss_ce_enc: 1.2860 (1.1891)  loss_bbox_enc: 0.0790 (0.1364)  loss_giou_enc: 0.3642 (0.5210)  loss_ce_unscaled: 1.3154 (1.2380)  class_error_unscaled: 87.5000 (93.4554)  loss_bbox_unscaled: 0.0144 (0.0226)  loss_giou_unscaled: 0.1779 (0.2263)  cardinality_error_unscaled: 3838.0000 (3853.4043)  loss_ce_0_unscaled: 1.3007 (1.2182)  loss_bbox_0_unscaled: 0.0147 (0.0249)  loss_giou_0_unscaled: 0.1821 (0.2403)  cardinality_error_0_unscaled: 3736.3750 (3800.2994)  loss_ce_enc_unscaled: 1.2860 (1.1891)  loss_bbox_enc_unscaled: 0.0158 (0.0273)  loss_giou_enc_unscaled: 0.1821 (0.2605)  cardinality_error_enc_unscaled: 3836.8750 (3728.8133)  time: 0.3430  data: 0.0207  max mem: 4861\n",
            "Epoch: [0]  [  90/1325]  eta: 0:07:33  lr: 0.000100  class_error: 90.14  loss: 5.2500 (5.4529)  loss_ce: 1.3154 (1.2445)  loss_bbox: 0.0780 (0.1094)  loss_giou: 0.3676 (0.4451)  loss_ce_0: 1.3007 (1.2256)  loss_bbox_0: 0.0780 (0.1200)  loss_giou_0: 0.3676 (0.4711)  loss_ce_enc: 1.2822 (1.1983)  loss_bbox_enc: 0.0812 (0.1312)  loss_giou_enc: 0.3769 (0.5076)  loss_ce_unscaled: 1.3154 (1.2445)  class_error_unscaled: 89.6635 (92.9266)  loss_bbox_unscaled: 0.0156 (0.0219)  loss_giou_unscaled: 0.1838 (0.2226)  cardinality_error_unscaled: 3860.0000 (3855.5824)  loss_ce_0_unscaled: 1.3007 (1.2256)  loss_bbox_0_unscaled: 0.0156 (0.0240)  loss_giou_0_unscaled: 0.1838 (0.2356)  cardinality_error_0_unscaled: 3810.5000 (3801.1511)  loss_ce_enc_unscaled: 1.2822 (1.1983)  loss_bbox_enc_unscaled: 0.0162 (0.0262)  loss_giou_enc_unscaled: 0.1885 (0.2538)  cardinality_error_enc_unscaled: 3844.7500 (3721.8365)  time: 0.3321  data: 0.0212  max mem: 4861\n",
            "Epoch: [0]  [ 100/1325]  eta: 0:07:28  lr: 0.000100  class_error: 84.13  loss: 5.2902 (5.4361)  loss_ce: 1.2971 (1.2502)  loss_bbox: 0.0795 (0.1066)  loss_giou: 0.3765 (0.4388)  loss_ce_0: 1.2956 (1.2324)  loss_bbox_0: 0.0820 (0.1162)  loss_giou_0: 0.3814 (0.4622)  loss_ce_enc: 1.2697 (1.2053)  loss_bbox_enc: 0.0884 (0.1268)  loss_giou_enc: 0.4037 (0.4976)  loss_ce_unscaled: 1.2971 (1.2502)  class_error_unscaled: 89.4231 (92.5083)  loss_bbox_unscaled: 0.0159 (0.0213)  loss_giou_unscaled: 0.1882 (0.2194)  cardinality_error_unscaled: 3876.1250 (3857.4431)  loss_ce_0_unscaled: 1.2956 (1.2324)  loss_bbox_0_unscaled: 0.0164 (0.0232)  loss_giou_0_unscaled: 0.1907 (0.2311)  cardinality_error_0_unscaled: 3810.5000 (3798.8899)  loss_ce_enc_unscaled: 1.2697 (1.2053)  loss_bbox_enc_unscaled: 0.0177 (0.0254)  loss_giou_enc_unscaled: 0.2019 (0.2488)  cardinality_error_enc_unscaled: 3858.6250 (3729.8614)  time: 0.3444  data: 0.0224  max mem: 4861\n",
            "Epoch: [0]  [ 110/1325]  eta: 0:07:23  lr: 0.000100  class_error: 78.37  loss: 5.2634 (5.4257)  loss_ce: 1.3106 (1.2542)  loss_bbox: 0.0760 (0.1046)  loss_giou: 0.3618 (0.4343)  loss_ce_0: 1.3045 (1.2380)  loss_bbox_0: 0.0766 (0.1134)  loss_giou_0: 0.3672 (0.4560)  loss_ce_enc: 1.2705 (1.2103)  loss_bbox_enc: 0.0860 (0.1239)  loss_giou_enc: 0.4020 (0.4911)  loss_ce_unscaled: 1.3106 (1.2542)  class_error_unscaled: 85.3598 (91.7013)  loss_bbox_unscaled: 0.0152 (0.0209)  loss_giou_unscaled: 0.1809 (0.2172)  cardinality_error_unscaled: 3876.3750 (3859.6824)  loss_ce_0_unscaled: 1.3045 (1.2380)  loss_bbox_0_unscaled: 0.0153 (0.0227)  loss_giou_0_unscaled: 0.1836 (0.2280)  cardinality_error_0_unscaled: 3793.6250 (3800.5169)  loss_ce_enc_unscaled: 1.2705 (1.2103)  loss_bbox_enc_unscaled: 0.0172 (0.0248)  loss_giou_enc_unscaled: 0.2010 (0.2455)  cardinality_error_enc_unscaled: 3860.0000 (3729.5349)  time: 0.3563  data: 0.0221  max mem: 4861\n",
            "Epoch: [0]  [ 120/1325]  eta: 0:07:20  lr: 0.000100  class_error: 75.24  loss: 5.2445 (5.4141)  loss_ce: 1.3162 (1.2584)  loss_bbox: 0.0761 (0.1026)  loss_giou: 0.3468 (0.4291)  loss_ce_0: 1.3270 (1.2441)  loss_bbox_0: 0.0766 (0.1108)  loss_giou_0: 0.3453 (0.4486)  loss_ce_enc: 1.2841 (1.2155)  loss_bbox_enc: 0.0880 (0.1212)  loss_giou_enc: 0.3809 (0.4837)  loss_ce_unscaled: 1.3162 (1.2584)  class_error_unscaled: 81.6377 (90.7514)  loss_bbox_unscaled: 0.0152 (0.0205)  loss_giou_unscaled: 0.1734 (0.2145)  cardinality_error_unscaled: 3891.2500 (3862.3740)  loss_ce_0_unscaled: 1.3270 (1.2441)  loss_bbox_0_unscaled: 0.0153 (0.0222)  loss_giou_0_unscaled: 0.1727 (0.2243)  cardinality_error_0_unscaled: 3863.5000 (3806.4153)  loss_ce_enc_unscaled: 1.2841 (1.2155)  loss_bbox_enc_unscaled: 0.0176 (0.0242)  loss_giou_enc_unscaled: 0.1904 (0.2419)  cardinality_error_enc_unscaled: 3858.2500 (3728.9184)  time: 0.3648  data: 0.0221  max mem: 4861\n",
            "Epoch: [0]  [ 130/1325]  eta: 0:07:16  lr: 0.000100  class_error: 79.57  loss: 5.2445 (5.4094)  loss_ce: 1.3032 (1.2587)  loss_bbox: 0.0784 (0.1014)  loss_giou: 0.3750 (0.4293)  loss_ce_0: 1.3100 (1.2465)  loss_bbox_0: 0.0765 (0.1090)  loss_giou_0: 0.3557 (0.4469)  loss_ce_enc: 1.2637 (1.2186)  loss_bbox_enc: 0.0880 (0.1189)  loss_giou_enc: 0.3826 (0.4802)  loss_ce_unscaled: 1.3032 (1.2587)  class_error_unscaled: 81.6377 (90.1968)  loss_bbox_unscaled: 0.0157 (0.0203)  loss_giou_unscaled: 0.1875 (0.2146)  cardinality_error_unscaled: 3891.8750 (3864.5267)  loss_ce_0_unscaled: 1.3100 (1.2465)  loss_bbox_0_unscaled: 0.0153 (0.0218)  loss_giou_0_unscaled: 0.1778 (0.2234)  cardinality_error_0_unscaled: 3866.5000 (3810.6994)  loss_ce_enc_unscaled: 1.2637 (1.2186)  loss_bbox_enc_unscaled: 0.0176 (0.0238)  loss_giou_enc_unscaled: 0.1913 (0.2401)  cardinality_error_enc_unscaled: 3853.5000 (3713.5095)  time: 0.3643  data: 0.0226  max mem: 4861\n",
            "Epoch: [0]  [ 140/1325]  eta: 0:07:11  lr: 0.000100  class_error: 84.86  loss: 5.2871 (5.4013)  loss_ce: 1.2607 (1.2589)  loss_bbox: 0.0789 (0.1003)  loss_giou: 0.3925 (0.4279)  loss_ce_0: 1.2955 (1.2485)  loss_bbox_0: 0.0782 (0.1076)  loss_giou_0: 0.3766 (0.4444)  loss_ce_enc: 1.2627 (1.2219)  loss_bbox_enc: 0.0845 (0.1167)  loss_giou_enc: 0.4029 (0.4751)  loss_ce_unscaled: 1.2607 (1.2589)  class_error_unscaled: 84.6154 (89.6019)  loss_bbox_unscaled: 0.0158 (0.0201)  loss_giou_unscaled: 0.1962 (0.2140)  cardinality_error_unscaled: 3892.5000 (3866.5044)  loss_ce_0_unscaled: 1.2955 (1.2485)  loss_bbox_0_unscaled: 0.0156 (0.0215)  loss_giou_0_unscaled: 0.1883 (0.2222)  cardinality_error_0_unscaled: 3866.1250 (3814.8014)  loss_ce_enc_unscaled: 1.2627 (1.2219)  loss_bbox_enc_unscaled: 0.0169 (0.0233)  loss_giou_enc_unscaled: 0.2014 (0.2375)  cardinality_error_enc_unscaled: 3848.3750 (3706.2287)  time: 0.3551  data: 0.0219  max mem: 4861\n",
            "Epoch: [0]  [ 150/1325]  eta: 0:07:07  lr: 0.000100  class_error: 76.68  loss: 5.2379 (5.3891)  loss_ce: 1.2777 (1.2611)  loss_bbox: 0.0779 (0.0988)  loss_giou: 0.3619 (0.4237)  loss_ce_0: 1.2987 (1.2522)  loss_bbox_0: 0.0764 (0.1055)  loss_giou_0: 0.3704 (0.4389)  loss_ce_enc: 1.2863 (1.2256)  loss_bbox_enc: 0.0828 (0.1143)  loss_giou_enc: 0.3822 (0.4690)  loss_ce_unscaled: 1.2777 (1.2611)  class_error_unscaled: 83.8942 (89.0544)  loss_bbox_unscaled: 0.0156 (0.0198)  loss_giou_unscaled: 0.1810 (0.2119)  cardinality_error_unscaled: 3893.2500 (3868.3825)  loss_ce_0_unscaled: 1.2987 (1.2522)  loss_bbox_0_unscaled: 0.0153 (0.0211)  loss_giou_0_unscaled: 0.1852 (0.2194)  cardinality_error_0_unscaled: 3877.3750 (3819.3692)  loss_ce_enc_unscaled: 1.2863 (1.2256)  loss_bbox_enc_unscaled: 0.0166 (0.0229)  loss_giou_enc_unscaled: 0.1911 (0.2345)  cardinality_error_enc_unscaled: 3859.5000 (3713.0414)  time: 0.3566  data: 0.0219  max mem: 4861\n",
            "Epoch: [0]  [ 160/1325]  eta: 0:07:03  lr: 0.000100  class_error: 89.58  loss: 5.1944 (5.3776)  loss_ce: 1.2862 (1.2625)  loss_bbox: 0.0745 (0.0974)  loss_giou: 0.3572 (0.4201)  loss_ce_0: 1.3147 (1.2554)  loss_bbox_0: 0.0716 (0.1037)  loss_giou_0: 0.3403 (0.4339)  loss_ce_enc: 1.2867 (1.2287)  loss_bbox_enc: 0.0793 (0.1122)  loss_giou_enc: 0.3680 (0.4638)  loss_ce_unscaled: 1.2862 (1.2625)  class_error_unscaled: 83.8942 (88.5171)  loss_bbox_unscaled: 0.0149 (0.0195)  loss_giou_unscaled: 0.1786 (0.2100)  cardinality_error_unscaled: 3892.8750 (3869.7873)  loss_ce_0_unscaled: 1.3147 (1.2554)  loss_bbox_0_unscaled: 0.0143 (0.0207)  loss_giou_0_unscaled: 0.1702 (0.2169)  cardinality_error_0_unscaled: 3877.3750 (3822.2772)  loss_ce_enc_unscaled: 1.2867 (1.2287)  loss_bbox_enc_unscaled: 0.0159 (0.0224)  loss_giou_enc_unscaled: 0.1840 (0.2319)  cardinality_error_enc_unscaled: 3867.1250 (3719.1281)  time: 0.3608  data: 0.0218  max mem: 4861\n",
            "Epoch: [0]  [ 170/1325]  eta: 0:06:58  lr: 0.000100  class_error: 77.64  loss: 5.2138 (5.3759)  loss_ce: 1.2834 (1.2624)  loss_bbox: 0.0765 (0.0971)  loss_giou: 0.3764 (0.4200)  loss_ce_0: 1.3044 (1.2569)  loss_bbox_0: 0.0721 (0.1033)  loss_giou_0: 0.3650 (0.4331)  loss_ce_enc: 1.2719 (1.2301)  loss_bbox_enc: 0.0843 (0.1114)  loss_giou_enc: 0.3867 (0.4613)  loss_ce_unscaled: 1.2834 (1.2624)  class_error_unscaled: 81.7949 (88.0785)  loss_bbox_unscaled: 0.0153 (0.0194)  loss_giou_unscaled: 0.1882 (0.2100)  cardinality_error_unscaled: 3892.7500 (3871.1564)  loss_ce_0_unscaled: 1.3044 (1.2569)  loss_bbox_0_unscaled: 0.0144 (0.0207)  loss_giou_0_unscaled: 0.1825 (0.2165)  cardinality_error_0_unscaled: 3873.6250 (3825.2471)  loss_ce_enc_unscaled: 1.2719 (1.2301)  loss_bbox_enc_unscaled: 0.0169 (0.0223)  loss_giou_enc_unscaled: 0.1933 (0.2307)  cardinality_error_enc_unscaled: 3868.5000 (3705.6016)  time: 0.3535  data: 0.0216  max mem: 4861\n",
            "Epoch: [0]  [ 180/1325]  eta: 0:06:53  lr: 0.000100  class_error: 79.65  loss: 5.2562 (5.3738)  loss_ce: 1.2636 (1.2617)  loss_bbox: 0.0878 (0.0969)  loss_giou: 0.3827 (0.4202)  loss_ce_0: 1.3000 (1.2579)  loss_bbox_0: 0.0841 (0.1028)  loss_giou_0: 0.3659 (0.4324)  loss_ce_enc: 1.2507 (1.2306)  loss_bbox_enc: 0.0956 (0.1108)  loss_giou_enc: 0.4082 (0.4604)  loss_ce_unscaled: 1.2636 (1.2617)  class_error_unscaled: 79.6526 (87.5326)  loss_bbox_unscaled: 0.0176 (0.0194)  loss_giou_unscaled: 0.1913 (0.2101)  cardinality_error_unscaled: 3893.8750 (3872.4006)  loss_ce_0_unscaled: 1.3000 (1.2579)  loss_bbox_0_unscaled: 0.0168 (0.0206)  loss_giou_0_unscaled: 0.1830 (0.2162)  cardinality_error_0_unscaled: 3879.7500 (3828.3004)  loss_ce_enc_unscaled: 1.2507 (1.2306)  loss_bbox_enc_unscaled: 0.0191 (0.0222)  loss_giou_enc_unscaled: 0.2041 (0.2302)  cardinality_error_enc_unscaled: 3866.6250 (3696.7106)  time: 0.3422  data: 0.0213  max mem: 4861\n",
            "Epoch: [0]  [ 190/1325]  eta: 0:06:49  lr: 0.000100  class_error: 75.24  loss: 5.2546 (5.3678)  loss_ce: 1.2346 (1.2609)  loss_bbox: 0.0884 (0.0964)  loss_giou: 0.4088 (0.4196)  loss_ce_0: 1.2842 (1.2584)  loss_bbox_0: 0.0831 (0.1020)  loss_giou_0: 0.3818 (0.4309)  loss_ce_enc: 1.2372 (1.2315)  loss_bbox_enc: 0.1002 (0.1098)  loss_giou_enc: 0.4167 (0.4583)  loss_ce_unscaled: 1.2346 (1.2609)  class_error_unscaled: 73.3333 (86.7737)  loss_bbox_unscaled: 0.0177 (0.0193)  loss_giou_unscaled: 0.2044 (0.2098)  cardinality_error_unscaled: 3894.7500 (3873.5831)  loss_ce_0_unscaled: 1.2842 (1.2584)  loss_bbox_0_unscaled: 0.0166 (0.0204)  loss_giou_0_unscaled: 0.1909 (0.2155)  cardinality_error_0_unscaled: 3882.5000 (3831.1603)  loss_ce_enc_unscaled: 1.2372 (1.2315)  loss_bbox_enc_unscaled: 0.0200 (0.0220)  loss_giou_enc_unscaled: 0.2083 (0.2292)  cardinality_error_enc_unscaled: 3866.7500 (3696.9208)  time: 0.3450  data: 0.0210  max mem: 4861\n",
            "Epoch: [0]  [ 200/1325]  eta: 0:06:46  lr: 0.000100  class_error: 90.14  loss: 5.1828 (5.3624)  loss_ce: 1.2459 (1.2602)  loss_bbox: 0.0750 (0.0959)  loss_giou: 0.3745 (0.4188)  loss_ce_0: 1.2872 (1.2595)  loss_bbox_0: 0.0747 (0.1012)  loss_giou_0: 0.3618 (0.4292)  loss_ce_enc: 1.2561 (1.2328)  loss_bbox_enc: 0.0811 (0.1088)  loss_giou_enc: 0.3978 (0.4560)  loss_ce_unscaled: 1.2459 (1.2602)  class_error_unscaled: 71.7122 (86.0950)  loss_bbox_unscaled: 0.0150 (0.0192)  loss_giou_unscaled: 0.1872 (0.2094)  cardinality_error_unscaled: 3895.2500 (3874.6629)  loss_ce_0_unscaled: 1.2872 (1.2595)  loss_bbox_0_unscaled: 0.0149 (0.0202)  loss_giou_0_unscaled: 0.1809 (0.2146)  cardinality_error_0_unscaled: 3882.7500 (3833.5989)  loss_ce_enc_unscaled: 1.2561 (1.2328)  loss_bbox_enc_unscaled: 0.0162 (0.0218)  loss_giou_enc_unscaled: 0.1989 (0.2280)  cardinality_error_enc_unscaled: 3866.1250 (3691.9341)  time: 0.3581  data: 0.0214  max mem: 4861\n",
            "Epoch: [0]  [ 210/1325]  eta: 0:06:42  lr: 0.000100  class_error: 64.27  loss: 5.1589 (5.3576)  loss_ce: 1.2453 (1.2588)  loss_bbox: 0.0762 (0.0957)  loss_giou: 0.3745 (0.4189)  loss_ce_0: 1.2822 (1.2594)  loss_bbox_0: 0.0747 (0.1006)  loss_giou_0: 0.3473 (0.4284)  loss_ce_enc: 1.2561 (1.2329)  loss_bbox_enc: 0.0840 (0.1082)  loss_giou_enc: 0.3978 (0.4549)  loss_ce_unscaled: 1.2453 (1.2588)  class_error_unscaled: 70.1923 (85.3713)  loss_bbox_unscaled: 0.0152 (0.0191)  loss_giou_unscaled: 0.1872 (0.2094)  cardinality_error_unscaled: 3895.1250 (3875.5877)  loss_ce_0_unscaled: 1.2822 (1.2594)  loss_bbox_0_unscaled: 0.0149 (0.0201)  loss_giou_0_unscaled: 0.1737 (0.2142)  cardinality_error_0_unscaled: 3881.8750 (3836.1191)  loss_ce_enc_unscaled: 1.2561 (1.2329)  loss_bbox_enc_unscaled: 0.0168 (0.0216)  loss_giou_enc_unscaled: 0.1989 (0.2274)  cardinality_error_enc_unscaled: 3858.3750 (3688.2168)  time: 0.3656  data: 0.0217  max mem: 4861\n",
            "Epoch: [0]  [ 220/1325]  eta: 0:06:39  lr: 0.000100  class_error: 66.83  loss: 5.1238 (5.3500)  loss_ce: 1.2258 (1.2568)  loss_bbox: 0.0797 (0.0950)  loss_giou: 0.3859 (0.4185)  loss_ce_0: 1.2576 (1.2589)  loss_bbox_0: 0.0752 (0.0997)  loss_giou_0: 0.3789 (0.4273)  loss_ce_enc: 1.2538 (1.2333)  loss_bbox_enc: 0.0820 (0.1072)  loss_giou_enc: 0.3967 (0.4532)  loss_ce_unscaled: 1.2258 (1.2568)  class_error_unscaled: 70.4327 (84.7791)  loss_bbox_unscaled: 0.0159 (0.0190)  loss_giou_unscaled: 0.1930 (0.2092)  cardinality_error_unscaled: 3894.1250 (3876.3835)  loss_ce_0_unscaled: 1.2576 (1.2589)  loss_bbox_0_unscaled: 0.0150 (0.0199)  loss_giou_0_unscaled: 0.1895 (0.2137)  cardinality_error_0_unscaled: 3890.6250 (3838.4700)  loss_ce_enc_unscaled: 1.2538 (1.2333)  loss_bbox_enc_unscaled: 0.0164 (0.0214)  loss_giou_enc_unscaled: 0.1984 (0.2266)  cardinality_error_enc_unscaled: 3849.8750 (3689.3450)  time: 0.3700  data: 0.0223  max mem: 4861\n",
            "Epoch: [0]  [ 230/1325]  eta: 0:06:37  lr: 0.000100  class_error: 68.27  loss: 5.1103 (5.3415)  loss_ce: 1.2217 (1.2555)  loss_bbox: 0.0750 (0.0944)  loss_giou: 0.3840 (0.4171)  loss_ce_0: 1.2588 (1.2591)  loss_bbox_0: 0.0726 (0.0989)  loss_giou_0: 0.3697 (0.4253)  loss_ce_enc: 1.2538 (1.2337)  loss_bbox_enc: 0.0804 (0.1063)  loss_giou_enc: 0.3967 (0.4512)  loss_ce_unscaled: 1.2217 (1.2555)  class_error_unscaled: 66.8269 (83.9368)  loss_bbox_unscaled: 0.0150 (0.0189)  loss_giou_unscaled: 0.1920 (0.2086)  cardinality_error_unscaled: 3894.7500 (3877.1986)  loss_ce_0_unscaled: 1.2588 (1.2591)  loss_bbox_0_unscaled: 0.0145 (0.0198)  loss_giou_0_unscaled: 0.1848 (0.2126)  cardinality_error_0_unscaled: 3891.2500 (3840.8155)  loss_ce_enc_unscaled: 1.2538 (1.2337)  loss_bbox_enc_unscaled: 0.0161 (0.0213)  loss_giou_enc_unscaled: 0.1984 (0.2256)  cardinality_error_enc_unscaled: 3830.7500 (3690.6385)  time: 0.3764  data: 0.0227  max mem: 4861\n",
            "Epoch: [0]  [ 240/1325]  eta: 0:06:34  lr: 0.000100  class_error: 51.44  loss: 5.0486 (5.3319)  loss_ce: 1.2101 (1.2533)  loss_bbox: 0.0801 (0.0939)  loss_giou: 0.3499 (0.4157)  loss_ce_0: 1.2569 (1.2589)  loss_bbox_0: 0.0730 (0.0982)  loss_giou_0: 0.3450 (0.4232)  loss_ce_enc: 1.2548 (1.2347)  loss_bbox_enc: 0.0850 (0.1055)  loss_giou_enc: 0.3827 (0.4486)  loss_ce_unscaled: 1.2101 (1.2533)  class_error_unscaled: 62.2596 (83.0972)  loss_bbox_unscaled: 0.0160 (0.0188)  loss_giou_unscaled: 0.1750 (0.2078)  cardinality_error_unscaled: 3895.3750 (3877.9461)  loss_ce_0_unscaled: 1.2569 (1.2589)  loss_bbox_0_unscaled: 0.0146 (0.0196)  loss_giou_0_unscaled: 0.1725 (0.2116)  cardinality_error_0_unscaled: 3891.2500 (3842.8548)  loss_ce_enc_unscaled: 1.2548 (1.2347)  loss_bbox_enc_unscaled: 0.0170 (0.0211)  loss_giou_enc_unscaled: 0.1914 (0.2243)  cardinality_error_enc_unscaled: 3805.8750 (3687.7744)  time: 0.3814  data: 0.0226  max mem: 4862\n",
            "Epoch: [0]  [ 250/1325]  eta: 0:06:31  lr: 0.000100  class_error: 57.45  loss: 5.0345 (5.3220)  loss_ce: 1.1862 (1.2507)  loss_bbox: 0.0779 (0.0934)  loss_giou: 0.3580 (0.4142)  loss_ce_0: 1.2502 (1.2582)  loss_bbox_0: 0.0742 (0.0975)  loss_giou_0: 0.3470 (0.4213)  loss_ce_enc: 1.2425 (1.2345)  loss_bbox_enc: 0.0876 (0.1051)  loss_giou_enc: 0.3848 (0.4471)  loss_ce_unscaled: 1.1862 (1.2507)  class_error_unscaled: 58.8942 (82.2457)  loss_bbox_unscaled: 0.0156 (0.0187)  loss_giou_unscaled: 0.1790 (0.2071)  cardinality_error_unscaled: 3895.5000 (3878.6519)  loss_ce_0_unscaled: 1.2502 (1.2582)  loss_bbox_0_unscaled: 0.0148 (0.0195)  loss_giou_0_unscaled: 0.1735 (0.2107)  cardinality_error_0_unscaled: 3889.8750 (3844.7351)  loss_ce_enc_unscaled: 1.2425 (1.2345)  loss_bbox_enc_unscaled: 0.0175 (0.0210)  loss_giou_enc_unscaled: 0.1924 (0.2235)  cardinality_error_enc_unscaled: 3794.7500 (3686.7973)  time: 0.3832  data: 0.0227  max mem: 4862\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrfdetr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RFDETRNano\n\u001b[32m      3\u001b[39m model = RFDETRNano()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_accum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/nvidia-da/poker-card/pk-env/lib/python3.12/site-packages/rfdetr/detr.py:81\u001b[39m, in \u001b[36mRFDETR.train\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[33;03mTrain an RF-DETR model.\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     80\u001b[39m config = \u001b[38;5;28mself\u001b[39m.get_train_config(**kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/nvidia-da/poker-card/pk-env/lib/python3.12/site-packages/rfdetr/detr.py:187\u001b[39m, in \u001b[36mRFDETR.train_from_config\u001b[39m\u001b[34m(self, config, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     early_stopping_callback = EarlyStoppingCallback(\n\u001b[32m    180\u001b[39m         model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    181\u001b[39m         patience=config.early_stopping_patience,\n\u001b[32m    182\u001b[39m         min_delta=config.early_stopping_min_delta,\n\u001b[32m    183\u001b[39m         use_ema=config.early_stopping_use_ema\n\u001b[32m    184\u001b[39m     )\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m.callbacks[\u001b[33m\"\u001b[39m\u001b[33mon_fit_epoch_end\u001b[39m\u001b[33m\"\u001b[39m].append(early_stopping_callback.update)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/nvidia-da/poker-card/pk-env/lib/python3.12/site-packages/rfdetr/main.py:341\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, callbacks, **kwargs)\u001b[39m\n\u001b[32m    339\u001b[39m model.train()\n\u001b[32m    340\u001b[39m criterion.train()\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m train_stats = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43meffective_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_max_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mema_m\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mema_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_training_steps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_training_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvit_encoder_num_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvit_encoder_num_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m train_epoch_time = time.time() - epoch_start_time\n\u001b[32m    347\u001b[39m train_epoch_time_str = \u001b[38;5;28mstr\u001b[39m(datetime.timedelta(seconds=\u001b[38;5;28mint\u001b[39m(train_epoch_time)))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/nvidia-da/poker-card/pk-env/lib/python3.12/site-packages/rfdetr/engine.py:139\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, criterion, lr_scheduler, data_loader, optimizer, device, epoch, batch_size, max_norm, ema_m, schedules, num_training_steps_per_epoch, vit_encoder_num_layers, args, callbacks)\u001b[39m\n\u001b[32m    131\u001b[39m         weight_dict = criterion.weight_dict\n\u001b[32m    132\u001b[39m         losses = \u001b[38;5;28msum\u001b[39m(\n\u001b[32m    133\u001b[39m             (\u001b[32m1\u001b[39m / args.grad_accum_steps) * loss_dict[k] * weight_dict[k]\n\u001b[32m    134\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m loss_dict.keys()\n\u001b[32m    135\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m weight_dict\n\u001b[32m    136\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# reduce losses over all GPUs for logging purposes\u001b[39;00m\n\u001b[32m    142\u001b[39m loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/nvidia-da/poker-card/pk-env/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/nvidia-da/poker-card/pk-env/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/nvidia-da/poker-card/pk-env/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from rfdetr import RFDETRNano\n",
        "\n",
        "model = RFDETRNano()\n",
        "\n",
        "model.train(dataset_dir=dataset.location, epochs=80, batch_size=8, grad_accum_steps=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRE_csKqxC9U"
      },
      "source": [
        "Before benchmarking the model, we need to load the best saved checkpoint. To ensure it fits on the GPU, we first need to free up GPU memory. This involves deleting any remaining references to previously used objects, triggering Python’s garbage collector, and clearing the CUDA memory cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSei0WZ8qt_5",
        "outputId": "a19e2391-2f58-46c2-ef36-538fc544ed8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Before] Allocated: 146.49 MB | Reserved: 10432.00 MB\n",
            "[WARNING] Object not fully garbage collected yet.\n",
            "[After]  Allocated: 146.49 MB | Reserved: 316.00 MB\n"
          ]
        }
      ],
      "source": [
        "cleanup_gpu_memory(model, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P1dYTMTYGT3"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <p>\n",
        "    Looking for more tutorials or have questions?\n",
        "    Check out our <a href=\"https://github.com/roboflow/notebooks\">GitHub repo</a> for more notebooks,\n",
        "    or visit our <a href=\"https://discord.gg/GbfgXGJ8Bk\">discord</a>.\n",
        "  </p>\n",
        "  \n",
        "  <p>\n",
        "    <strong>If you found this helpful, please consider giving us a ⭐\n",
        "    <a href=\"https://github.com/roboflow/notebooks\">on GitHub</a>!</strong>\n",
        "  </p>\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pk-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
